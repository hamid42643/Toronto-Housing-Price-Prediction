{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIyjrkrRv6kF6YX/rlQjJt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamid42643/Toronto-Housing-Price-Prediction/blob/main/Friedel_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-rKfAAD9nhQ-",
        "outputId": "9289ef2b-7eec-452d-acdd-7b2abbeb909e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-155da967ff7f>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mshap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-155da967ff7f>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.csv'"
          ]
        }
      ],
      "source": [
        "#Assignment 3.1: Seeing the Forest for the Trees\n",
        "#Introduction\n",
        "\n",
        "#In machine learning, it is vital that the right algorithm be used based on the business problem and characteristics of the data. In the industry, models are often combined or cascaded to form model ensembles to achieve defined objectives. This assignment will familiarize you with the iterative process to do that.\n",
        "#Instructions\n",
        "\n",
        "    #Build a single classification tree using Python using no more than 20 variables.\n",
        "        #NOTE: You can use some of the variables you chose from the Assignment 1.1, or completely new ones. Prune the tree if necessary. Plot the tree visualization.\n",
        "    #Build a RandomForest model using Python using no more than 20 variables, these can be the same variables from the single decision tree, or completely new ones. The same variables will allow for an easier comparison. Explain any differences that you observe between the RandomForest Model and the Single Decision Tree.\n",
        "    #Compare the model performance and generalization of the two models. Explain if/why you see the differences.\n",
        "    #Data Processing\n",
        "from sklearn import tree # Import Tree Classifiers\n",
        "from sklearn.ensemble import RandomForestClassifier # Import Random Forest Classifiers\n",
        "from sklearn.model_selection import train_test_split,  RandomizedSearchCV # Import train_test_split function\n",
        "from sklearn import metrics # Import scikit-learn metrics module for accuracy calculation\n",
        "from scipy.stats import randint # Generate random numbers\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import norm, skew\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def load_dataset(filename):\n",
        "    df = pd.read_csv(filename)\n",
        "    return df\n",
        "df = load_dataset(\"train_data.csv\")\n",
        "\n",
        "shap = df.shape\n",
        "print(\"Shape of the dataframe (row, col):\",shap,\"\\r\\n\")\n",
        "\n",
        "# Show the dataframe\n",
        "df\n",
        "\n",
        "#Clean Data\n",
        "# Missing values\n",
        "missing_count = df.isnull().sum()\n",
        "missing_count\n",
        "\n",
        "# Total of missing values\n",
        "total_cells = np.product(df.shape)\n",
        "total_missing = df.isnull().sum().sum()\n",
        "\n",
        "# Percentage of missing data\n",
        "(total_missing/total_cells) * 100\n",
        "\n",
        "# Replace missing values with 0\n",
        "df = df.fillna(0)\n",
        "\n",
        "#display the first 5 rows in dataset:\n",
        "df.head(5)\n",
        "\n",
        "#shows the data type of each column, number of columns, memory usage, and the number of records in the dataset:\n",
        "df.info()\n",
        "\n",
        "#display the number of records and columns:\n",
        "df.shape\n",
        "\n",
        "#summarize the dataset’s statistical properties, such as count, mean, min, and max:\n",
        "df.describe()\n",
        "\n",
        "# Convert enuerations to integer\n",
        "del df['OCCUPATION_TYPE']\n",
        "del df['ORGANIZATION_TYPE']\n",
        "df[\"HOUSETYPE_MODE\"] = df['HOUSETYPE_MODE'].replace({'block of flats': 1, 'terraced house': 2, 'specific housing': 3}).astype(int)\n",
        "df[\"FONDKAPREMONT_MODE\"] = df['FONDKAPREMONT_MODE'].replace({'reg oper account': 1, 'org spec account': 2, 'reg oper spec account': 3, 'not specified': 4}).astype(int)\n",
        "df[\"NAME_HOUSING_TYPE\"] = df['NAME_HOUSING_TYPE'].replace({'House / apartment': 1, 'Municipal apartment': 2, 'Office apartment': 3, 'Rented apartment': 4, 'With parents': 5, 'Co-op apartment':6}).astype(int)\n",
        "df[\"NAME_EDUCATION_TYPE\"] = df['NAME_EDUCATION_TYPE'].replace({'Secondary / secondary special': 1, 'Higher education': 2, 'Lower secondary': 3, 'Incomplete higher': 4, 'Academic degree': 5}).astype(int)\n",
        "df[\"NAME_INCOME_TYPE\"] = df['NAME_INCOME_TYPE'].replace({'Working': 1, 'Pensioner': 2, 'Commercial associate': 3, 'State servant': 4, 'Unemployed': 5, 'Businessman': 6, 'Student': 7, 'Maternity leave': 7}).astype(int)\n",
        "df[\"NAME_TYPE_SUITE\"] = df['NAME_TYPE_SUITE'].replace({'Unaccompanied': 1, 'Family': 2, 'Children': 3, 'Spouse, partner': 4, 'Other_A': 5, 'Other_B': 6, 'Group of people': 7}).astype(int)\n",
        "df[\"NAME_FAMILY_STATUS\"] = df['NAME_FAMILY_STATUS'].replace({'Married': 1, 'Single / not married': 2, 'Civil marriage': 3, 'Widow': 4, 'Separated': 5, 'Unknown': 6, 'Others': 7}).astype(int)\n",
        "df[\"WALLSMATERIAL_MODE\"] = df['WALLSMATERIAL_MODE'].replace({'Panel': 1, 'Wooden': 2, 'Stone, brick': 3, 'Block': 4, 'Mixed': 5, 'Monolithic': 6, 'Others': 7, 'Unknown': 8}).astype(int)\n",
        "df[\"EMERGENCYSTATE_MODE\"] = df['EMERGENCYSTATE_MODE'].replace({'No': 1, 'Yes': 2}).astype(int)\n",
        "df[\"FLAG_OWN_CAR\"] = df['FLAG_OWN_CAR'].replace({'N': 0, 'Y': 1}).astype(int)\n",
        "df[\"FLAG_OWN_REALTY\"] = df['FLAG_OWN_REALTY'].replace({'N': 0, 'Y': 1}).astype(int)\n",
        "df[\"CODE_GENDER\"] = df['CODE_GENDER'].replace({'M': 0, 'F': 1}).astype(int)\n",
        "df[\"NAME_CONTRACT_TYPE\"] = df['NAME_CONTRACT_TYPE'].replace({'Cash loans': 0, 'Revolving loans': 1}).astype(int)\n",
        "df[\"WEEKDAY_APPR_PROCESS_START\"] = df['WEEKDAY_APPR_PROCESS_START'].replace({'MONDAY': 1, 'TUESDAY': 2, 'WEDNESDAY': 3, 'THURSDAY': 4, 'FRIDAY': 5, 'SATURDAY': 6, 'SUNDAY': 7}).astype(int)\n",
        "#display the first 5 rows in dataset:\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None\n",
        "df.head(5)\n",
        "\n",
        "#display the correlation between different variables in dataset:\n",
        "df.corr()\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "\n",
        "X=pd.DataFrame(df)\n",
        "\n",
        "print(X.head())\n",
        "\n",
        "# Select features\n",
        "features = ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_GOODS_PRICE', 'AMT_ANNUITY', 'DAYS_EMPLOYED', 'OWN_CAR_AGE', 'NAME_FAMILY_STATUS']\n",
        "#features = ['AMT_INCOME_TOTAL']\n",
        "X_selected = X[features]\n",
        "\n",
        "# Select Target\n",
        "y = X['TARGET']\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize the classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "#@title Designating target and features\n",
        "y = df.TARGET # Target variable\n",
        "df = df.drop(columns=['TARGET']) # Features by dropping the target column\n",
        "columns_to_drop = list(range(11, 119))\n",
        "columns_to_drop_names = df.columns[columns_to_drop]\n",
        "X =  df.drop(columns=columns_to_drop_names)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test/valid\n",
        "\n",
        "\n",
        "\n",
        "# Decision Tree\n",
        "# ---------------------------------------------------------------\n",
        "#@title Building the Decision Tree\n",
        "clf = tree.DecisionTreeClassifier() # Create Decision Tree classifer object\n",
        "clf = clf.fit(X_train, y_train) # Train Decision Tree Classifer\n",
        "\n",
        "#@title Evaluating the Tree model\n",
        "y_hat = clf.predict(X_train) # Predict the response for train dataset\n",
        "\n",
        "y_pred = clf.predict(X_test) # Predict the response for test dataset\n",
        "\n",
        "# Compute training and test accuracy\n",
        "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_hat))\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#@title Visualizing the Tree\n",
        "\n",
        "f_names=list(X.columns) # Feature names\n",
        "tree.plot_tree(clf, filled=True, feature_names=f_names) # Plot the tree\n",
        "plt.show() # Show without the rules in plain text\n",
        "\n",
        "# Create Decision Tree classifer object by spefifying parameters\n",
        "# Try using max_depth=3, min_samples_split=100, min_samples_leaf=2, criterion=\"entropy\"\n",
        "clf = tree.DecisionTreeClassifier(max_depth=3, min_samples_leaf=2, criterion='entropy')\n",
        "\n",
        "# Train and test the classifier\n",
        "clf = clf.fit(X_train, y_train) # Train Decision Tree Classifer\n",
        "y_hat = clf.predict(X_train) # Predict the response for train dataset\n",
        "y_pred = clf.predict(X_test) # Predict the response for test dataset\n",
        "\n",
        "# Compute training and test accuracy\n",
        "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_hat))\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "plt.rcParams['figure.dpi'] = 200 # To increase the resolution from 100dpi to 200dpi\n",
        "\n",
        "# Plot the tree\n",
        "f_names=list(X.columns) # Feature names\n",
        "tree.plot_tree(clf, filled=True, feature_names=f_names) # Plot the tree\n",
        "plt.show() # Show without the rules in plain text\n",
        "\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "#---------------------------------------------------------------------\n",
        "#@title Building the Random Forest\n",
        "\n",
        "rf = RandomForestClassifier(random_state=100) # Create Fandom Forest classifer object\n",
        "rf = rf.fit(X_train, y_train) # Train Random Forest Classifer\n",
        "#@title Evaluating the RF model\n",
        "y_hat = rf.predict(X_train) # Predict the response for train dataset\n",
        "\n",
        "y_pred = rf.predict(X_test) # Predict the response for test dataset\n",
        "\n",
        "# Compute training and test accuracy\n",
        "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_hat))\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#@title Visualizing few trees of the RF\n",
        "\n",
        "f_names=list(X.columns) # Feature names\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(10,2), dpi=3000) # Setup the 1x5 grid for ploting the trees\n",
        "for index in range(0, 5): # Iterate through the first five trees (of 100)\n",
        "  tree.plot_tree(rf.estimators_[index], feature_names=f_names, filled = True, ax=axes[index]); # Plot the tree\n",
        "  axes[index].set_title('Estimator: ' + str(index), fontsize = 11) # Print title\n",
        "\n",
        "#@title Tuning the RF\n",
        "# Create RF classifer object by spefifying parameters\n",
        "# Try using n_estimators=200, max_depth=2\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=2, random_state=0) # Create Random Forest classifer object\n",
        "rf = rf.fit(X_train, y_train) # Train Random Forest Classifer\n",
        "\n",
        "# Train and test the classifier\n",
        "rf = rf.fit(X_train, y_train) # Train Decision Tree Classifer\n",
        "y_hat = rf.predict(X_train) # Predict the response for train dataset\n",
        "y_pred = rf.predict(X_test) # Predict the response for test dataset\n",
        "\n",
        "# Compute training and test accuracy\n",
        "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_hat))\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#@title Hyperparameter search\n",
        "param_dist = {'n_estimators': randint(50,500), 'max_depth': randint(1,20)} # Search ranges\n",
        "rf = RandomForestClassifier() # Create a random forest classifier\n",
        "rand_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=5, cv=5) # Use random search to find the best hyperparameters\n",
        "rand_search.fit(X_train, y_train) # Fit the random search object to the training data\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:',  rand_search.best_params_)\n",
        "\n",
        "best_rf = rand_search.best_estimator_ # Capture the best model\n",
        "y_hat = best_rf.predict(X_train) # Predict the response for train dataset\n",
        "y_pred = best_rf.predict(X_test) # Predict the response for test dataset\n",
        "\n",
        "# Compute training and test accuracy\n",
        "print(\"Train Accuracy:\", metrics.accuracy_score(y_train, y_hat))\n",
        "print(\"Test Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "#@title More Evaluation Metrics\n",
        "\n",
        "print(\"Precision:\", metrics.precision_score(y_test, y_pred, average = 'weighted')) # Note - multi-class problem so not straight forward!\n",
        "print(\"Recall:\", metrics.recall_score(y_test, y_pred, average = 'weighted')) # Note - multi-class problem so not straight forward!\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "metrics.ConfusionMatrixDisplay(confusion_matrix=cm).plot();\n",
        "\n",
        "#Comparison:\n",
        "#The Random Forest Test Accuracy was 0.92 versus the Tree’s 0.84.  However, when the Tree was optimized, its accuracy also reached 0.92.\n",
        "#The tree with Optimization seems the most efficient process, because it achieved the same accuracy, and did not crash my PC,\n",
        "#like Random Forest did!"
      ]
    }
  ]
}